{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Manager\n",
    "\n",
    "Resource Manager lets you hierarchically manage resources by Project, Folder and Organization. \n",
    "\n",
    "Policies contain a set of roles and members and policies are set on resources. These resources inherit policies from their parent thus resources policies are union of parent and resouces. If the parent policy is less restrictive it overrides more restrictive resource policy. \n",
    "\n",
    "Although IAM policies are inherited from top to bottom, Billing is accumulated from the bottom up. Resources consumption is measure in quantities like rate of use or time, number of items or feature use. Because a resource belongs to only one project, a project accumulates the consumption or all its resources each project is associated with one billing account, which means organization contains all billing accounts. \n",
    "\n",
    "Since project accumulates consumption of all its resources it can be used to track resource and quota usage. Projects specifically lets you enable billing, manage permissions and credentials and enaable services and API.\n",
    "\n",
    "To interact with Cloud Platform resources you must provide the identifying project information for every request. A project can be identified by Project name which is a human readable way to identify projects. Project Number which is automatically generated by the server and assigned to your project and the project id which is a unique id which is generated from your project name. You can find these three attributes on the dashboard of your GCP console or by querying resource manager API.\n",
    "\n",
    "From a physical organization stand point resources are categorized as Global, Regional or Zonal.\n",
    "Images snapshots and networks are global resources, External IP addresses are regional resources and Instances and Disks are zonal resources. However Regardless of the type each resource is organized into a project, this enables for each project to have its own billing and reporting. \n",
    "\n",
    "![title](CloudResourceManager.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Quotas\n",
    "\n",
    "All resources in GCP are subject to projects quotas or limits. These typically fall into one of the three categories shown here. \n",
    "* How many resources you can create per project ex - You can have only have 5VPC Networks per project.\n",
    "* How quickly you can make API requests in a project: Rate Limit. For example by default you cana make 5 administrative actions per second per project when using cloud spanner API.\n",
    "* How many resources you can create per region for example by default you can only have 24 CPU's per region. \n",
    "\n",
    "As your use of GCP services increase over time your quotas may increase accordingly. If you expect a notable upcoming increase in usage you can proactively request quota adjustments from the quotas page in the GCP console. This page will also display your current quotas. \n",
    "\n",
    "What is the need for quotas.\n",
    "* Project Quotas prevent runaway consumption in case of a error or a malicious attack, For example imagine you create 100 instances instead of 10 using the GCloud Command.\n",
    "* Quotas also prevent billing spikes or surprises.\n",
    "* Quotas force sizing considerations and periodic review.\n",
    "\n",
    "Quotas are the maximim amount of resources you can create for that resource type as long as those resources are available, Quotas do not guarantee that resources are available at all times. For example if a region are out or local ssd's you cannot create local ssd in that region even if you still had quota for local ssd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lables and Names\n",
    "\n",
    "Projects and folders provide levels of segregation for resources but what if you want more granularity that is where lables and names come in. Lables are a utility for organizing GCP Resources. Lables are key value pairs that you can attach to your resources like VM, Disk, Snap Shots and Disks. \n",
    "\n",
    "You can create and manage lables using the GCP console, GCloud or the resource manager API and each resource can have upto 64 lables. For example you can create a lable to define the environment of your virtual machines then you define the lable for each of your machines instances either as production or test. Using these lables you can search and list all of your production resources for inventory purposes. Lables can also be used in scripts to analyze cost or run bulk operations on multiple resources \n",
    "\n",
    "Example Uses of Lables\n",
    "\n",
    "* Teams and Cost Centers - This will help distinguish instances owned by different teams.\n",
    "* Components - Like a FrontEnd, Redis Etc.\n",
    "* Environment or Stage - Production and Development and Test.\n",
    "* Owner or Primary Contact \n",
    "* State - Like InUse, ReadyForDeletion\n",
    "\n",
    "Lables are user defines strings in Key Value Format that are used to organize resources and they can propogate through billing. Tags are user defines strings that are applied to Instances only and are manily used for networking for applying firewall rules. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Billing\n",
    "\n",
    "Consumption of all resources under a project accumulates into one billing account. To help with project planning and controlling cost you can setup budget, setting up budget lets you track how your spend is growing towards that amount.\n",
    "\n",
    "![title](Budget.PNG)\n",
    "\n",
    "First you specify a Budget Name and specify which project this budget this applies to. Then you can set the budget at a specific amount or match it to the previous month spend. After you determine your budget amount you can set the budget alerts, these alerts send alerts to billing admins after the spend exceeds a percentage of the budget or specified amount. You can set to send an alert when the spend is forecasted to exceed % of budget amount by the end of the budget period. In addition to recieving an email you can use Cloud Pub/Sub Notifications to programatically recieve spend updates about this budget, you can even create a cloud function that listens to the cloud pubsub Topic to automate cost management. \n",
    "\n",
    "You can analyze the spend by making use of Lables to query resources and their spend \n",
    "Example -\n",
    "Select TO_JSON_STRING(lables) as Lables,SUM(Cost) as Cost\n",
    "FROM Project.Dataset.Table\n",
    "Group By lables\n",
    "\n",
    "This will give you spend per Resource Lable.\n",
    "\n",
    "You can also visualize spend over time with data studio. Data Studio turns your data into informative dashboard and reports that are easy to read, easy to share and fully customizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Quiz\n",
    "\n",
    "![title](ModuleQuiz2.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource Monitoring\n",
    "\n",
    "Stack Driver is a service that provides monitoring, Logging and diagnostics for your application. \n",
    "\n",
    "Stack Driver dynamically discovers cloud resources and application services based on deep integration with Google Platform and Amazon Web Services because of its smart defaults you can have core visibility into your cloud platform in mins. This provides you access to powerful data and analytics tool and colaboration with many different third party software providers.\n",
    "\n",
    "Stack Deiver has services for Monitoring, Logging, Error Reporting Fault Tracing and Debugging, You only pay for what you use and there are free usage allotments so that you can get started with no upfront fee or commitment. \n",
    "\n",
    "In most other environments these services are handled by completly different packages or by a loosely integrated collection of software when you see these functions working together in a single comprehensive and integrated service you will realize how important that is to creating reliable stable and maintainable applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring\n",
    "\n",
    "Monitoring is important to google because it is at the base of Site Reliability Engineering. SRE is a discipline that applies aspects of software engineering to operations whose goals are to create ultra scalable highly reliable software systems this discipline has enabled google to build, deploy, monitor and maintain some of the largest sotware systems in the world.\n",
    "\n",
    "Stack Driver dynamically configures monitoring after resources are deployed and has intelligent defaults that allow you to easily create charts for basic monitoring activity. This allows you to monitor your platform, System and application metrics, by ingesting data such as metrics, events and metadata. You can then generate insights from this data through dashboards, charts and alerts. For example you can configure and measure uptimes and health checks and send alerts via email. \n",
    "\n",
    "A Workspace is a root entity that holds monitoring and configuration information in StackDriver Monitoring. Each Workspace can have between 1 and 100 monitored projects. Including one or more GCP projects and any number of AWS accounts. You can have as many work spaces as you want but GCP projects and AWS Accounts can be monitored by more than one work space.\n",
    "\n",
    "A Workspace contains custom dashboards, alerting policies, Uptime Checks, Notification Channels and Group Definitions that you use with your monitored projects. A work space can access metric data from its monitored projects but the measured data and the log entries remain in the inndividual projects. \n",
    "\n",
    "The first monitored GCP project in the workspace is called the hosting project and it must be specified when you create a workspace and the name of that project becomes the name of the workspace. To access an AWS account you must configure a project in GCP to host the AWS connector. \n",
    "\n",
    "Because your WorkSpace can monitor all your projects in a single place a workspace is a single pane of glass through which you can view resources from multiple GCP projects and AWS accounts. All Stack Driver users who have access to that work space have access to all data by default, This means that a stackdriver role assigned to one person one on one project applies equally to all projects monitored by that work space. In order to give people different roles per project and to control visibility in data consider placing the monitoring of those projects in separate work spaces. \n",
    "\n",
    "Stack Driver Monitoring allows you to create custom dashboards that contain charts of the metrics that you want to monitor For Example you can create charts that monitor the CPU utilization of your instance.\n",
    "\n",
    "Although Charts are extremely useful they can only provide insight when someone is looking at them, what if your server goes down in the middle of the night or over the weekend you cannot have someone monitoring metrics 24/7. Thus you can create alerting policies that notify you when specific conditions are met. \n",
    "\n",
    "Best Practice when setting up Alerts\n",
    "* Alert on Symptoms and not causes - Example you want to monitor failing queries of databases and then identify if the database is down. \n",
    "* Make sure you are using multiple notification channels like email and SMS. This avoids single point of failure on your alerting strategies. \n",
    "* Customize your alerts to the audience need, by describing what actions need to be taken or what resources need to be examined. \n",
    "* Avoid Noise - This will cause alerts to be dismissed over time, specifically adjust monitoring alerts so that they are actionable and dont setup alerts on everything possible.\n",
    "\n",
    "Uptime checks can be configured to test availability of your public services from locations around the world. For each uptime check you can setup alerting policy and view the latancy of each global location.\n",
    "\n",
    "Stack Driver Monitoring can access some metrics without the monitoring agent including CPU Utilization, some Disk Traffic Metrics network traffic and uptime infotrmation. To access additional system resources and application services you should install monitoring agent. Monitoring Agent is supported for compute engine and EC2 Instances \n",
    "\n",
    "If the standard mentics provided by stack driver monitoring do not fit your needs you can create custom metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging, Error Reporting, Tracing and Debugging.\n",
    "\n",
    "## Logging\n",
    "\n",
    "Stack Driver Logging allows you to store, Search, analyze, Monitor and Alert on log data and events from GCP and AWS. Is is a fully managed service that performs at scale and can ingest appliaction and system log data from thousands of VMs. Logging includes storage for logs, user interface called logs viewer and an API to manage logs programatically. The service lets you read and write log entries search and filter logs and create log based metrics. \n",
    "\n",
    "Logs are only retained for 30 days but you can export your logs to cloud storage bucket, BigQuery datasets and Cloud Pub/Sub Topics. Exporting logs to cloud storage makes sense for storing logs for more than 30 days, Exporting logs to BigQuery allows you to analyze logs and and visualize them in data studio. BigQuery runs extremly fast SQL queries on GB to PB of data this allows you to analyze logs such aas your network traffic so that you can better understand traffic growth to forecast capacity, network usage to optimize network traffic expenses or network forensics to analyze incidents. If you want to visualize your logs you can connect your BigQuery tables to datastudio. Data Studio transforms your raw data into the metrics and dimensions that you can use to create an easy to understand reports and dashboards. You can also export logs to cloud Pud/Sub this enables you to stream logs to applications or endpoints.\n",
    "\n",
    "Similar to stack drivers monitoring agent, it is best practice to install logging agent on all of your VM instances. This agent is supported for compute engine and ec2 instances \n",
    "\n",
    "## Error Reporting\n",
    "\n",
    "Stack Driver Error Reporting counts, analyzes and aggregates the error in your running cloud services. Centralized error management interface displays the results with sorting and filtering capabilities. You can even setup real time notifications when new errors are detected. In terms of programming languages the exception stack trace parser is able to process GO, Java, .NET, Node.js, PHP, Python, Ruby\n",
    "\n",
    "## Tracing\n",
    "\n",
    "Tracing is another stack driver feature integrated into GCP. Stack Driver Trace is a distributed tracing system that collects latancy data from your application and displays it in the GCP console. You can track how request propagate through your application and recieve detail and near realtime performance insights. Stack Driver Trace automatically analyzes all of your application's traces to generate indepth latancy reports that surface performance degradation and can capture traces from app engine HTTPS load balancer and applications instrumented with Stack Driver Trace API. Managing the amount of time it takes for your application to handle incoming requests and perform operations is an important part of managing overall application performance. Stack Driver Trace is actaully based on the tools used at Google to keep our services running at extreme scale. \n",
    "\n",
    "## Debugging\n",
    "\n",
    "Stack driver Debugger is a feture of GCP that lets you inspect the state of a running application in real time without stopping or slowing it, specifically debugger adds less than 10ms to the request latancy when the application state is captured, in most cases this is noticible by users. These features allow you to understand the behavior of your code in production and analyze its state to locate those hard to find bugs. With just a few mouse clicks you can take a snapshot of your running application state or inject new logging statement. Stack Debugger support multiple languages including GO, Java, .NET, Node.js, Python, Ruby\n",
    "\n",
    "![title](ModuleQuiz3.PNG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
